{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\.conda\\envs\\tensor_ali\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Ali\\.conda\\envs\\tensor_ali\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Ali\\.conda\\envs\\tensor_ali\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "pd.set_option(\"max_columns\",100)\n",
    "pd.set_option('display.width',1000)\n",
    "pd.set_option('max_colwidth', 1000) \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status information</th>\n",
       "      <th>Clean-status</th>\n",
       "      <th>clean_sent</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raja</td>\n",
       "      <td>hyderabad</td>\n",
       "      <td>0</td>\n",
       "      <td>14/8/prema: share me details, available in evng 18/8/prema: postponed the plans for training currently 9/11/prema: not interested now</td>\n",
       "      <td>[prema, share, detail, available, evng, prema, postpone, plan, train, currently, prema, not, interest]</td>\n",
       "      <td>prema share detail available evng prema postpone plan train currently prema not interest</td>\n",
       "      <td>hyderabad prema share detail available evng prema postpone plan train currently prema not interest Raja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anirudh Reddy</td>\n",
       "      <td>pune</td>\n",
       "      <td>0</td>\n",
       "      <td>14/8/prema: cal me tmrw, shared details to email 16/8/prema: share details to email, will check n revert 18/8/prema: received your email, i'm looking for ASQ certification</td>\n",
       "      <td>[prema, cal, share, detail, email, prema, share, detail, email, check, n, revert, prema, receive, email, look, asq, certification]</td>\n",
       "      <td>prema cal share detail email prema share detail email check n revert prema receive email look asq certification</td>\n",
       "      <td>pune prema cal share detail email prema share detail email check n revert prema receive email look asq certification Anirudh Reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sapna Dewani</td>\n",
       "      <td>bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>16|AuG|moHan:rnr</td>\n",
       "      <td>[aug, mohan, rnr]</td>\n",
       "      <td>aug mohan rnr</td>\n",
       "      <td>bangalore aug mohan rnr Sapna Dewani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suresh</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>0</td>\n",
       "      <td>14/8/17(Surendra):i want only Server 16|AuG|moHan:cal busy 17|AuG|moHan:reg for server</td>\n",
       "      <td>[surendra, want, server, aug, mohan, cal, busy, aug, mohan, reg, server]</td>\n",
       "      <td>surendra want server aug mohan cal busy aug mohan reg server</td>\n",
       "      <td>mumbai surendra want server aug mohan cal busy aug mohan reg server suresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akshay Shinde</td>\n",
       "      <td>hyderabad</td>\n",
       "      <td>0</td>\n",
       "      <td>14/8/prema:rnr 16/8/prema: gave info, he said he will revert in 1hr 30/8/prema: planning for next month, share details</td>\n",
       "      <td>[prema, rnr, prema, give, info, say, revert, hr, prema, plan, next, month, share, detail]</td>\n",
       "      <td>prema rnr prema give info say revert hr prema plan next month share detail</td>\n",
       "      <td>hyderabad prema rnr prema give info say revert hr prema plan next month share detail Akshay Shinde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lead Name   Location  Status                                                                                                                                                            Status information                                                                                                                        Clean-status                                                                                                       clean_sent                                                                                                                                Text\n",
       "0           Raja  hyderabad        0                                        14/8/prema: share me details, available in evng 18/8/prema: postponed the plans for training currently 9/11/prema: not interested now                              [prema, share, detail, available, evng, prema, postpone, plan, train, currently, prema, not, interest]                         prema share detail available evng prema postpone plan train currently prema not interest                             hyderabad prema share detail available evng prema postpone plan train currently prema not interest Raja\n",
       "1  Anirudh Reddy       pune        0  14/8/prema: cal me tmrw, shared details to email 16/8/prema: share details to email, will check n revert 18/8/prema: received your email, i'm looking for ASQ certification  [prema, cal, share, detail, email, prema, share, detail, email, check, n, revert, prema, receive, email, look, asq, certification]  prema cal share detail email prema share detail email check n revert prema receive email look asq certification  pune prema cal share detail email prema share detail email check n revert prema receive email look asq certification Anirudh Reddy\n",
       "2   Sapna Dewani  bangalore        1                                                                                                                                                             16|AuG|moHan:rnr                                                                                                                   [aug, mohan, rnr]                                                                                                    aug mohan rnr                                                                                                bangalore aug mohan rnr Sapna Dewani\n",
       "3         suresh     mumbai        0                                                                                       14/8/17(Surendra):i want only Server 16|AuG|moHan:cal busy 17|AuG|moHan:reg for server                                                            [surendra, want, server, aug, mohan, cal, busy, aug, mohan, reg, server]                                                     surendra want server aug mohan cal busy aug mohan reg server                                                          mumbai surendra want server aug mohan cal busy aug mohan reg server suresh\n",
       "4  Akshay Shinde  hyderabad        0                                                       14/8/prema:rnr 16/8/prema: gave info, he said he will revert in 1hr 30/8/prema: planning for next month, share details                                           [prema, rnr, prema, give, info, say, revert, hr, prema, plan, next, month, share, detail]                                       prema rnr prema give info say revert hr prema plan next month share detail                                  hyderabad prema rnr prema give info say revert hr prema plan next month share detail Akshay Shinde"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join('C:/BEPEC Python Material/NLP project/','Clean_data.pkl')\n",
    "df = pd.read_pickle(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(739,)\n",
      "(185,)\n",
      "(739,)\n",
      "(185,)\n",
      "0    161\n",
      "1     24\n",
      "Name: Status , dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(df['Text'],df['Status '],test_size = 0.2,random_state = 42,shuffle= True,\n",
    "                                                      stratify = df['Status '])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(df):\n",
    "    corpus=[]\n",
    "    for text in tqdm(df):\n",
    "        words=[word for word in word_tokenize(text)]\n",
    "        corpus.append(words)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 739/739 [00:00<00:00, 3282.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 185/185 [00:00<00:00, 3777.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['mumbai',\n",
       "  'surendra',\n",
       "  'call',\n",
       "  'hour',\n",
       "  'surendra',\n",
       "  'rnr',\n",
       "  'surendra',\n",
       "  'sit',\n",
       "  'work',\n",
       "  'confirm',\n",
       "  'time',\n",
       "  'surendra',\n",
       "  'check',\n",
       "  'tomorrow',\n",
       "  'pm',\n",
       "  'session',\n",
       "  'surendra',\n",
       "  'come',\n",
       "  'pm',\n",
       "  'today',\n",
       "  'surendra',\n",
       "  'already',\n",
       "  'do',\n",
       "  'Vikas'],\n",
       " ['hyderabad',\n",
       "  'june',\n",
       "  'mohan',\n",
       "  'rnr',\n",
       "  'nd',\n",
       "  'cal',\n",
       "  'latr',\n",
       "  'june',\n",
       "  'mohan',\n",
       "  'rnr',\n",
       "  'nd',\n",
       "  'not',\n",
       "  'intrstd',\n",
       "  'june',\n",
       "  'mohan',\n",
       "  'rnr',\n",
       "  'june',\n",
       "  'mohan',\n",
       "  'rnr',\n",
       "  'july',\n",
       "  'mohan',\n",
       "  'rnr',\n",
       "  'Akansha'],\n",
       " ['hyderabad',\n",
       "  'july',\n",
       "  'mohan',\n",
       "  'rnr',\n",
       "  'july',\n",
       "  'mohan',\n",
       "  'not',\n",
       "  'july',\n",
       "  'mohan',\n",
       "  'cal',\n",
       "  'evng',\n",
       "  'aug',\n",
       "  'mohan',\n",
       "  'not',\n",
       "  'intrtstd',\n",
       "  'Vipra',\n",
       "  'Deshpande'],\n",
       " ['bangalore',\n",
       "  'surendra',\n",
       "  'iam',\n",
       "  'available',\n",
       "  'next',\n",
       "  'week',\n",
       "  'tuesday',\n",
       "  'morning',\n",
       "  'better',\n",
       "  'attend',\n",
       "  'trail',\n",
       "  'sessions',\n",
       "  'please',\n",
       "  'send',\n",
       "  'detail',\n",
       "  'prema',\n",
       "  'pm',\n",
       "  'check',\n",
       "  'call',\n",
       "  'prema',\n",
       "  'need',\n",
       "  'call',\n",
       "  'pm',\n",
       "  'prema',\n",
       "  'rnr',\n",
       "  'prema',\n",
       "  'right',\n",
       "  'pursue',\n",
       "  'sas',\n",
       "  'may',\n",
       "  'b',\n",
       "  'months',\n",
       "  'may',\n",
       "  'plan',\n",
       "  'Varun',\n",
       "  'Sharma'],\n",
       " ['bihar',\n",
       "  'prema',\n",
       "  'share',\n",
       "  'detail',\n",
       "  'need',\n",
       "  'cal',\n",
       "  'later',\n",
       "  'pm',\n",
       "  'prema',\n",
       "  'rnr',\n",
       "  'gowtham',\n",
       "  'not',\n",
       "  'intrsd',\n",
       "  'madhuri']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus = create_corpus(X_train)\n",
    "test_corpus = create_corpus(X_test)\n",
    "test_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33,\n",
       "  2,\n",
       "  8,\n",
       "  420,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  429,\n",
       "  100,\n",
       "  70,\n",
       "  42,\n",
       "  2,\n",
       "  17,\n",
       "  31,\n",
       "  29,\n",
       "  24,\n",
       "  2,\n",
       "  35,\n",
       "  29,\n",
       "  21,\n",
       "  2,\n",
       "  58,\n",
       "  78],\n",
       " [12,\n",
       "  15,\n",
       "  4,\n",
       "  1,\n",
       "  39,\n",
       "  26,\n",
       "  154,\n",
       "  15,\n",
       "  4,\n",
       "  1,\n",
       "  39,\n",
       "  9,\n",
       "  36,\n",
       "  15,\n",
       "  4,\n",
       "  1,\n",
       "  15,\n",
       "  4,\n",
       "  1,\n",
       "  11,\n",
       "  4,\n",
       "  1,\n",
       "  967],\n",
       " [12, 11, 4, 1, 11, 4, 9, 11, 4, 26, 59, 20, 4, 9, 538, 1356],\n",
       " [10,\n",
       "  2,\n",
       "  28,\n",
       "  87,\n",
       "  73,\n",
       "  83,\n",
       "  1627,\n",
       "  61,\n",
       "  115,\n",
       "  27,\n",
       "  163,\n",
       "  84,\n",
       "  54,\n",
       "  55,\n",
       "  7,\n",
       "  3,\n",
       "  29,\n",
       "  17,\n",
       "  8,\n",
       "  3,\n",
       "  18,\n",
       "  8,\n",
       "  29,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  219,\n",
       "  285,\n",
       "  531,\n",
       "  16,\n",
       "  112,\n",
       "  144,\n",
       "  16,\n",
       "  77,\n",
       "  1061,\n",
       "  282],\n",
       " [3, 6, 7, 18, 26, 48, 29, 3, 1, 13, 9, 113]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_obj = Tokenizer() \n",
    "tokenizer_obj.fit_on_texts(train_corpus) # methods `texts_to_sequences` or `texts_to_matrix`.\n",
    "train_sequences=tokenizer_obj.texts_to_sequences(train_corpus) # Transforms each text in texts to a sequence of integers.\n",
    "test_sequences=tokenizer_obj.texts_to_sequences(test_corpus)\n",
    "\n",
    "test_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739\n",
      "(739, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   37,   22,  564],\n",
       "       [   0,    0,    0, ...,   30,  565,  391],\n",
       "       [   0,    0,    0, ...,   38,  566,  567],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1651, 1652, 1653],\n",
       "       [   0,    0,    0, ...,  102,  148, 1655],\n",
       "       [   0,    0,    0, ...,    6,    7,  274]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad=pad_sequences(train_sequences,maxlen=50,truncating='post',padding='pre') # lists to array form\n",
    "test_pad=pad_sequences(test_sequences,maxlen=50,truncating='post',padding='pre')\n",
    "\n",
    "print(len(train_corpus))\n",
    "print(train_pad.shape)\n",
    "train_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 1656\n"
     ]
    }
   ],
   "source": [
    "word_index=tokenizer_obj.word_index\n",
    "lenght = len(word_index)+1\n",
    "print('Number of unique words:',lenght)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  We will be training 2 different NLP models 1 learns embedding from scratch and 2 uses pre-trained embedding and finnaly we see the performance of both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WE have to downgrade our numpy outherwise the below cell will give a NotImplementedError\n",
    "#pip install numpy==1.19.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           165600    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50, 128)           117248    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 291,169\n",
      "Trainable params: 291,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DIM = 100\n",
    "MAX_LEN = 50\n",
    "model = Sequential()\n",
    "\n",
    "## Embedding layer\n",
    "model.add(Embedding(lenght , DIM , input_length = MAX_LEN , trainable=True))\n",
    "model.compile('adam' , 'mse')\n",
    "\n",
    "## LSTM layer\n",
    "model.add(LSTM(128,return_sequences=True,dropout=0.2))\n",
    "\n",
    "#Global Maxpooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model.add(Dense(64,activation='relu')) \n",
    "model.add(Dense(1,activation='sigmoid')) \n",
    "\n",
    "#Add loss function, metrics, optimizer\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[\"acc\"]) \n",
    "\n",
    "#Adding callbacks\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)\n",
    "\n",
    "#Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 7s 612ms/step - loss: 0.6575 - acc: 0.8573 - val_loss: 0.5168 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87027, saving model to best_model.h5\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 221ms/step - loss: 0.4667 - acc: 0.8638 - val_loss: 0.4088 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.87027\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 219ms/step - loss: 0.3884 - acc: 0.8757 - val_loss: 0.3875 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.87027\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 2s 299ms/step - loss: 0.3986 - acc: 0.8685 - val_loss: 0.3854 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.87027\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 230ms/step - loss: 0.4012 - acc: 0.8622 - val_loss: 0.3823 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87027\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 223ms/step - loss: 0.3918 - acc: 0.8669 - val_loss: 0.3817 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87027\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 253ms/step - loss: 0.3666 - acc: 0.8781 - val_loss: 0.3833 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87027\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 2s 290ms/step - loss: 0.3876 - acc: 0.8667 - val_loss: 0.3826 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87027\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 251ms/step - loss: 0.3967 - acc: 0.8595 - val_loss: 0.3805 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.87027\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 228ms/step - loss: 0.3829 - acc: 0.8645 - val_loss: 0.3832 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.87027\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(train_pad),np.array(y_train),batch_size=128,epochs=10,\n",
    "                    validation_data=(np.array(test_pad),np.array(y_test)),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 71ms/step - loss: 0.5210 - acc: 0.8674\n",
      "0.8673883676528931\n"
     ]
    }
   ],
   "source": [
    "#loading best model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "#evaluation \n",
    "_,val_acc = model.evaluate(train_pad,y_train, batch_size=128)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[641,   0],\n",
       "       [ 98,   0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict_classes(X_test) to get classes directly\n",
    "y_pred = model.predict(train_pad)\n",
    "y_pred = (y_pred > 0.5)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train , y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[161,   0],\n",
       "       [ 24,   0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_pad)\n",
    "y_pred = (y_pred > 0.5)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test , y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using-pre trained model (glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing words....\n"
     ]
    }
   ],
   "source": [
    "GLOVE_DIR = 'C:/Users/Ali/Downloads/glove.6B_2'\n",
    "print(\"indexing words....\")\n",
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "\n",
    "f = open(os.path.join(GLOVE_DIR , glove_input_file),encoding='utf8')\n",
    "embedding_index = {}\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    ceof = np.asarray(values[1:] , dtype = 'float32')\n",
    "    embedding_index[word] = ceof\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnr 1\n",
      "surendra 2\n",
      "prema 3\n",
      "mohan 4\n",
      "soma 5\n",
      "share 6\n",
      "detail 7\n",
      "call 8\n",
      "not 9\n",
      "bangalore 10\n",
      "july 11\n",
      "hyderabad 12\n",
      "gowtham 13\n",
      "demo 14\n",
      "june 15\n",
      "may 16\n",
      "check 17\n",
      "need 18\n",
      "join 19\n",
      "aug 20\n",
      "today 21\n",
      "back 22\n",
      "want 23\n",
      "session 24\n",
      "busy 25\n",
      "cal 26\n",
      "attend 27\n",
      "iam 28\n",
      "pm 29\n",
      "interest 30\n",
      "tomorrow 31\n",
      "u 32\n",
      "mumbai 33\n",
      "pune 34\n",
      "come 35\n",
      "intrstd 36\n",
      "get 37\n",
      "connect 38\n",
      "nd 39\n",
      "mail 40\n",
      "classroom 41\n",
      "time 42\n",
      "try 43\n",
      "ct 44\n",
      "delhi 45\n",
      "revert 46\n",
      "link 47\n",
      "later 48\n",
      "n 49\n",
      "weekend 50\n",
      "switch 51\n",
      "even 52\n",
      "wil 53\n",
      "please 54\n",
      "send 55\n",
      "ask 56\n",
      "disconnect 57\n",
      "already 58\n",
      "evng 59\n",
      "know 60\n",
      "morning 61\n",
      "reachable 62\n",
      "look 63\n",
      "us 64\n",
      "say 65\n",
      "let 66\n",
      "train 67\n",
      "swtch 68\n",
      "email 69\n",
      "confirm 70\n",
      "reachble 71\n",
      "month 72\n",
      "next 73\n",
      "batch 74\n",
      "go 75\n",
      "monday 76\n",
      "plan 77\n",
      "do 78\n",
      "online 79\n",
      "chennai 80\n",
      "cls 81\n",
      "inform 82\n",
      "week 83\n",
      "sessions 84\n",
      "trainer 85\n",
      "mrg 86\n",
      "available 87\n",
      "number 88\n",
      "webinar 89\n",
      "apr 90\n",
      "kumar 91\n",
      "present 92\n",
      "aftr 93\n",
      "th 94\n",
      "record 95\n",
      "meet 96\n",
      "issue 97\n",
      "mrng 98\n",
      "course 99\n",
      "work 100\n",
      "travel 101\n",
      "institute 102\n",
      "dont 103\n",
      "ofc 104\n",
      "enrol 105\n",
      "singh 106\n",
      "nxt 107\n",
      "due 108\n",
      "unable 109\n",
      "coverage 110\n",
      "area 111\n",
      "b 112\n",
      "intrsd 113\n",
      "days 114\n",
      "better 115\n",
      "alrdy 116\n",
      "sms 117\n",
      "dis 118\n",
      "w 119\n",
      "cmng 120\n",
      "finalise 121\n",
      "cnfrm 122\n",
      "currently 123\n",
      "mnth 124\n",
      "ravi 125\n",
      "tableau 126\n",
      "k 127\n",
      "noida 128\n",
      "august 129\n",
      "saturday 130\n",
      "another 131\n",
      "intimate 132\n",
      "krishna 133\n",
      "take 134\n",
      "discuss 135\n",
      "job 136\n",
      "id 137\n",
      "far 138\n",
      "postpone 139\n",
      "rajesh 140\n",
      "gurgoan 141\n",
      "suresh 142\n",
      "talk 143\n",
      "months 144\n",
      "cnnctng 145\n",
      "new 146\n",
      "atend 147\n",
      "vishal 148\n",
      "give 149\n",
      "shrd 150\n",
      "ds 151\n",
      "gurgaon 152\n",
      "payment 153\n",
      "latr 154\n",
      "marow 155\n",
      "tim 156\n",
      "reddy 157\n",
      "gaurav 158\n",
      "hr 159\n",
      "require 160\n",
      "office 161\n",
      "sai 162\n",
      "trail 163\n",
      "videos 164\n",
      "frnd 165\n",
      "town 166\n",
      "think 167\n",
      "patil 168\n",
      "project 169\n",
      "management 170\n",
      "text 171\n",
      "regard 172\n",
      "day 173\n",
      "soon 174\n",
      "l 175\n",
      "respnd 176\n",
      "frshr 177\n",
      "speak 178\n",
      "mnths 179\n",
      "inst 180\n",
      "plz 181\n",
      "ok 182\n",
      "discus 183\n",
      "room 184\n",
      "inquire 185\n",
      "home 186\n",
      "amit 187\n",
      "sure 188\n",
      "wrong 189\n",
      "ashish 190\n",
      "srinivas 191\n",
      "sri 192\n",
      "free 193\n",
      "station 194\n",
      "data 195\n",
      "attnd 196\n",
      "drive 197\n",
      "comfortable 198\n",
      "python 199\n",
      "server 200\n",
      "abdul 201\n",
      "provide 202\n",
      "decide 203\n",
      "nov 204\n",
      "plng 205\n",
      "mndy 206\n",
      "didnt 207\n",
      "shankar 208\n",
      "sandeep 209\n",
      "student 210\n",
      "venkat 211\n",
      "afternoon 212\n",
      "register 213\n",
      "still 214\n",
      "weknd 215\n",
      "gupta 216\n",
      "shinde 217\n",
      "nedded 218\n",
      "right 219\n",
      "raja 220\n",
      "trial 221\n",
      "problem 222\n",
      "todays 223\n",
      "pavan 224\n",
      "wife 225\n",
      "info 226\n",
      "wan 227\n",
      "possible 228\n",
      "code 229\n",
      "othr 230\n",
      "connection 231\n",
      "satdy 232\n",
      "dat 233\n",
      "arun 234\n",
      "cant 235\n",
      "prashant 236\n",
      "drop 237\n",
      "fresher 238\n",
      "psbl 239\n",
      "ml 240\n",
      "wk 241\n",
      "friday 242\n",
      "voice 243\n",
      "near 244\n",
      "sometime 245\n",
      "amar 246\n",
      "rchble 247\n",
      "atteded 248\n",
      "attnded 249\n",
      "siva 250\n",
      "prakash 251\n",
      "ni 252\n",
      "vacation 253\n",
      "abt 254\n",
      "shaik 255\n",
      "gng 256\n",
      "cut 257\n",
      "yah 258\n",
      "kiran 259\n",
      "shift 260\n",
      "rd 261\n",
      "class 262\n",
      "change 263\n",
      "pmp 264\n",
      "mohammed 265\n",
      "schedule 266\n",
      "wll 267\n",
      "clsrom 268\n",
      "enquire 269\n",
      "st 270\n",
      "internship 271\n",
      "raj 272\n",
      "nt 273\n",
      "rahul 274\n",
      "abhishek 275\n",
      "process 276\n",
      "sachin 277\n",
      "na 278\n",
      "india 279\n",
      "unregistered 280\n",
      "weeknd 281\n",
      "sharma 282\n",
      "venue 283\n",
      "minz 284\n",
      "pursue 285\n",
      "vinay 286\n",
      "contact 287\n",
      "yet 288\n",
      "sunil 289\n",
      "prjts 290\n",
      "deepak 291\n",
      "hosp 292\n",
      "frnds 293\n",
      "reg 294\n",
      "mid 295\n",
      "akshay 296\n",
      "misd 297\n",
      "kunal 298\n",
      "wrng 299\n",
      "pathak 300\n",
      "ill 301\n",
      "weekdays 302\n",
      "vijay 303\n",
      "company 304\n",
      "learn 305\n",
      "divya 306\n",
      "wid 307\n",
      "complete 308\n",
      "excelr 309\n",
      "token 310\n",
      "deatils 311\n",
      "hometown 312\n",
      "vijayawada 313\n",
      "priyanka 314\n",
      "prasad 315\n",
      "intermediate 316\n",
      "sudhakar 317\n",
      "vgp 318\n",
      "layout 319\n",
      "also 320\n",
      "banglore 321\n",
      "address 322\n",
      "anand 323\n",
      "shubham 324\n",
      "price 325\n",
      "money 326\n",
      "p 327\n",
      "requirements 328\n",
      "attende 329\n",
      "numbr 330\n",
      "swtchd 331\n",
      "post 332\n",
      "last 333\n",
      "hadoop 334\n",
      "medium 335\n",
      "couple 336\n",
      "exclr 337\n",
      "analytics 338\n",
      "mind 339\n",
      "anil 340\n",
      "cmpny 341\n",
      "dubey 342\n",
      "mis 343\n",
      "joind 344\n",
      "ankur 345\n",
      "science 346\n",
      "himanshu 347\n",
      "naveen 348\n",
      "sorry 349\n",
      "first 350\n",
      "college 351\n",
      "flexible 352\n",
      "place 353\n",
      "ajay 354\n",
      "hyd 355\n",
      "vishakapatnam 356\n",
      "surya 357\n",
      "madhu 358\n",
      "friend 359\n",
      "itil 360\n",
      "network 361\n",
      "business 362\n",
      "ram 363\n",
      "clsroom 364\n",
      "students 365\n",
      "fridy 366\n",
      "client 367\n",
      "rashmi 368\n",
      "pankaj 369\n",
      "usa 370\n",
      "accept 371\n",
      "move 372\n",
      "live 373\n",
      "traffic 374\n",
      "research 375\n",
      "ssgb 376\n",
      "every 377\n",
      "dys 378\n",
      "pln 379\n",
      "tool 380\n",
      "arrange 381\n",
      "hindi 382\n",
      "audible 383\n",
      "vivek 384\n",
      "rom 385\n",
      "syed 386\n",
      "bad 387\n",
      "s 388\n",
      "search 389\n",
      "dnt 390\n",
      "roy 391\n",
      "phn 392\n",
      "statistical 393\n",
      "analysis 394\n",
      "city 395\n",
      "sharath 396\n",
      "mahesh 397\n",
      "whn 398\n",
      "return 399\n",
      "harish 400\n",
      "santhosh 401\n",
      "clasroom 402\n",
      "lokng 403\n",
      "kaushik 404\n",
      "abroad 405\n",
      "ramesh 406\n",
      "chiranjeevi 407\n",
      "ajith 408\n",
      "lakshmi 409\n",
      "october 410\n",
      "mohit 411\n",
      "way 412\n",
      "com 413\n",
      "cert 414\n",
      "shw 415\n",
      "shiva 416\n",
      "brthr 417\n",
      "ali 418\n",
      "directly 419\n",
      "hour 420\n",
      "sekhar 421\n",
      "offer 422\n",
      "raghu 423\n",
      "would 424\n",
      "shashi 425\n",
      "num 426\n",
      "rohit 427\n",
      "nasik 428\n",
      "sit 429\n",
      "ghazibad 430\n",
      "certification 431\n",
      "wks 432\n",
      "yadav 433\n",
      "clock 434\n",
      "afterwards 435\n",
      "video 436\n",
      "profile 437\n",
      "anoop 438\n",
      "tody 439\n",
      "make 440\n",
      "keerthi 441\n",
      "base 442\n",
      "exp 443\n",
      "ahmedabad 444\n",
      "good 445\n",
      "wen 446\n",
      "akshaya 447\n",
      "hav 448\n",
      "per 449\n",
      "hemanth 450\n",
      "mint 451\n",
      "satya 452\n",
      "aurangabad 453\n",
      "sugstd 454\n",
      "venkatesh 455\n",
      "november 456\n",
      "placement 457\n",
      "much 458\n",
      "part 459\n",
      "desktop 460\n",
      "enrld 461\n",
      "karunakar 462\n",
      "light 463\n",
      "kumari 464\n",
      "priya 465\n",
      "wek 466\n",
      "req 467\n",
      "khan 468\n",
      "teja 469\n",
      "cntcd 470\n",
      "fr 471\n",
      "error 472\n",
      "short 473\n",
      "phani 474\n",
      "bro 475\n",
      "jun 476\n",
      "oct 477\n",
      "addres 478\n",
      "devops 479\n",
      "sample 480\n",
      "till 481\n",
      "sql 482\n",
      "approval 483\n",
      "naga 484\n",
      "chaitanya 485\n",
      "endng 486\n",
      "rupam 487\n",
      "respndg 488\n",
      "manoj 489\n",
      "prvdng 490\n",
      "bhaskar 491\n",
      "shft 492\n",
      "blw 493\n",
      "kolkatta 494\n",
      "msg 495\n",
      "sir 496\n",
      "previous 497\n",
      "health 498\n",
      "vinod 499\n",
      "mostly 500\n",
      "gud 501\n",
      "clas 502\n",
      "kishore 503\n",
      "gopal 504\n",
      "conduct 505\n",
      "swamy 506\n",
      "wkend 507\n",
      "saurabh 508\n",
      "chck 509\n",
      "jain 510\n",
      "minal 511\n",
      "kanth 512\n",
      "nagaraju 513\n",
      "sumit 514\n",
      "query 515\n",
      "r 516\n",
      "sankar 517\n",
      "guntur 518\n",
      "vaibhav 519\n",
      "chat 520\n",
      "september 521\n",
      "v 522\n",
      "agenda 523\n",
      "sanjay 524\n",
      "verma 525\n",
      "cald 526\n",
      "many 527\n",
      "wait 528\n",
      "btwn 529\n",
      "misg 530\n",
      "sas 531\n",
      "anup 532\n",
      "karthik 533\n",
      "bite 534\n",
      "two 535\n",
      "reacahble 536\n",
      "havng 537\n",
      "intrtstd 538\n",
      "vishwanath 539\n",
      "cme 540\n",
      "murali 541\n",
      "trning 542\n",
      "lkng 543\n",
      "upto 544\n",
      "nitin 545\n",
      "praveen 546\n",
      "avinash 547\n",
      "weeks 548\n",
      "shilpa 549\n",
      "wiil 550\n",
      "hari 551\n",
      "sinha 552\n",
      "frm 553\n",
      "ankit 554\n",
      "aditya 555\n",
      "ankan 556\n",
      "pramod 557\n",
      "fine 558\n",
      "experience 559\n",
      "shoaib 560\n",
      "surekha 561\n",
      "swtchoff 562\n",
      "jitendra 563\n",
      "hiren 564\n",
      "sajal 565\n",
      "nikhil 566\n",
      "futane 567\n",
      "barun 568\n",
      "dev 569\n",
      "detaills 570\n",
      "pooja 571\n",
      "tthuse 572\n",
      "kothawade 573\n",
      "concern 574\n",
      "stats 575\n",
      "choudary 576\n",
      "aiswarya 577\n",
      "outside 578\n",
      "electronic 579\n",
      "prash 580\n",
      "santosh 581\n",
      "sidharth 582\n",
      "mehra 583\n",
      "travell 584\n",
      "bnlgr 585\n",
      "trupti 586\n",
      "rajamundry 587\n",
      "detailstomorrow 588\n",
      "rechd 589\n",
      "hom 590\n",
      "lat 591\n",
      "timng 592\n",
      "sn 593\n",
      "msc 594\n",
      "bio 595\n",
      "tech 596\n",
      "prog 597\n",
      "udaya 598\n",
      "sree 599\n",
      "claaroom 600\n",
      "cloud 601\n",
      "compute 602\n",
      "iot 603\n",
      "d 604\n",
      "confrm 605\n",
      "prsntly 606\n",
      "wii 607\n",
      "parent 608\n",
      "swati 609\n",
      "saudamini 610\n",
      "alomost 611\n",
      "traning 612\n",
      "shahrukh 613\n",
      "pal 614\n",
      "swthd 615\n",
      "subhani 616\n",
      "renuka 617\n",
      "marag 618\n",
      "habibullah 619\n",
      "trang 620\n",
      "postpond 621\n",
      "rakesh 622\n",
      "meenansha 623\n",
      "ph 624\n",
      "richa 625\n",
      "jaiswa 626\n",
      "hometwn 627\n",
      "tuesdy 628\n",
      "eachble 629\n",
      "ravikiran 630\n",
      "mayank 631\n",
      "devender 632\n",
      "yogendhar 633\n",
      "aparna 634\n",
      "murthy 635\n",
      "prabhu 636\n",
      "rotational 637\n",
      "chepayala 638\n",
      "sujoy 639\n",
      "priyadarshani 640\n",
      "sandhya 641\n",
      "tell 642\n",
      "chekc 643\n",
      "niranjan 644\n",
      "basic 645\n",
      "makarand 646\n",
      "propably 647\n",
      "rt 648\n",
      "itilf 649\n",
      "bakrid 650\n",
      "mubasshir 651\n",
      "nagpur 652\n",
      "sakshi 653\n",
      "soi 654\n",
      "interestd 655\n",
      "vidya 656\n",
      "end 657\n",
      "londhe 658\n",
      "spcl 659\n",
      "alekhya 660\n",
      "jisha 661\n",
      "pulak 662\n",
      "detaisl 663\n",
      "jagadish 664\n",
      "anshul 665\n",
      "garg 666\n",
      "maail 667\n",
      "roja 668\n",
      "shalini 669\n",
      "pawar 670\n",
      "global 671\n",
      "sk 672\n",
      "fareid 673\n",
      "avail 674\n",
      "shrey 675\n",
      "jalandhar 676\n",
      "aasawari 677\n",
      "jubin 678\n",
      "roshan 679\n",
      "mba 680\n",
      "sometym 681\n",
      "khwaja 682\n",
      "suman 683\n",
      "offfice 684\n",
      "statn 685\n",
      "sabyasachi 686\n",
      "sengupta 687\n",
      "attned 688\n",
      "bharat 689\n",
      "high 690\n",
      "jst 691\n",
      "jaipaul 692\n",
      "neema 693\n",
      "someshwar 694\n",
      "harshavardhan 695\n",
      "jus 696\n",
      "equired 697\n",
      "kalpana 698\n",
      "alok 699\n",
      "rayagada 700\n",
      "deatails 701\n",
      "kor 702\n",
      "mongo 703\n",
      "db 704\n",
      "atleast 705\n",
      "nasir 706\n",
      "inshort 707\n",
      "rahulraj 708\n",
      "khevna 709\n",
      "desai 710\n",
      "employee 711\n",
      "trainers 712\n",
      "quotation 713\n",
      "organisation 714\n",
      "scenarios 715\n",
      "differ 716\n",
      "dibyendu 717\n",
      "intrrstd 718\n",
      "srinivasan 719\n",
      "nikam 720\n",
      "debasish 721\n",
      "period 722\n",
      "dhirajkumar 723\n",
      "mar 724\n",
      "dsn 725\n",
      "exit 726\n",
      "toay 727\n",
      "sadiya 728\n",
      "avalable 729\n",
      "amol 730\n",
      "badgujar 731\n",
      "dutt 732\n",
      "simachal 733\n",
      "oin 734\n",
      "swayam 735\n",
      "pone 736\n",
      "anamika 737\n",
      "hv 738\n",
      "michael 739\n",
      "umesh 740\n",
      "siraj 741\n",
      "arfath 742\n",
      "wagh 743\n",
      "relatives 744\n",
      "arrive 745\n",
      "december 746\n",
      "assistance 747\n",
      "mounika 748\n",
      "kalyanam 749\n",
      "big 750\n",
      "parag 751\n",
      "ion 752\n",
      "perd 753\n",
      "girish 754\n",
      "h 755\n",
      "gaonkar 756\n",
      "market 757\n",
      "field 758\n",
      "program 759\n",
      "shivakumar 760\n",
      "srikant 761\n",
      "rout 762\n",
      "laptop 763\n",
      "b.srikanth 764\n",
      "havent 765\n",
      "yellender 766\n",
      "renu 767\n",
      "malik 768\n",
      "wanr 769\n",
      "embed 770\n",
      "wednesday 771\n",
      "ravichandra 772\n",
      "jeereddy 773\n",
      "sarah 774\n",
      "sarvijit 775\n",
      "muskaan 776\n",
      "maini 777\n",
      "aws 778\n",
      "plcd 779\n",
      "vaccation 780\n",
      "tharun 781\n",
      "ankita 782\n",
      "infromed 783\n",
      "weeek 784\n",
      "charankumar 785\n",
      "foundation 786\n",
      "moumita 787\n",
      "atul 788\n",
      "jaswanth 789\n",
      "rajani 790\n",
      "sumitha 791\n",
      "nitu 792\n",
      "sneha 793\n",
      "krishnamurthy 794\n",
      "spolen 795\n",
      "database 796\n",
      "rashid 797\n",
      "kolli 798\n",
      "jagadeesh 799\n",
      "gitika 800\n",
      "das 801\n",
      "signal 802\n",
      "arvindh 803\n",
      "seema 804\n",
      "diksha 805\n",
      "falg 806\n",
      "sajjad 807\n",
      "bysy 808\n",
      "rusthum 809\n",
      "rodney 810\n",
      "lewis 811\n",
      "vasu 812\n",
      "ranga 813\n",
      "dhiraj 814\n",
      "kr 815\n",
      "resend 816\n",
      "nishant 817\n",
      "avik 818\n",
      "bakshi 819\n",
      "prabir 820\n",
      "sistr 821\n",
      "law 822\n",
      "demp 823\n",
      "vipin 824\n",
      "net 825\n",
      "abhinav 826\n",
      "best 827\n",
      "advance 828\n",
      "topics 829\n",
      "dushyant 830\n",
      "punyashloke 831\n",
      "panigrahy 832\n",
      "subbarao 833\n",
      "prajna 834\n",
      "shetty 835\n",
      "vamshi 836\n",
      "ashwini 837\n",
      "weekedays 838\n",
      "anusha 839\n",
      "bussy 840\n",
      "attneded 841\n",
      "dmo 842\n",
      "hasija 843\n",
      "mobile 844\n",
      "furkhan 845\n",
      "ad 846\n",
      "khader 847\n",
      "paln 848\n",
      "balachandra 849\n",
      "parvath 850\n",
      "detials 851\n",
      "mem 852\n",
      "prefer 853\n",
      "simplilearn 854\n",
      "ankush 855\n",
      "set 856\n",
      "hamida 857\n",
      "nw 858\n",
      "raza 859\n",
      "abbas 860\n",
      "aniruddha 861\n",
      "majumdar 862\n",
      "ward 863\n",
      "mahammad 864\n",
      "hanif 865\n",
      "thane 866\n",
      "detais 867\n",
      "pradyut 868\n",
      "saisuseela 869\n",
      "adusumilli 870\n",
      "chaithra 871\n",
      "uae 872\n",
      "prathap 873\n",
      "participants 874\n",
      "maneesh 875\n",
      "pratham 876\n",
      "raizada 877\n",
      "start 878\n",
      "initialy 879\n",
      "scheduke 880\n",
      "deliverables 881\n",
      "remind 882\n",
      "gopi 883\n",
      "chand 884\n",
      "manish 885\n",
      "rajak 886\n",
      "padmanabha 887\n",
      "pradhip 888\n",
      "anupam 889\n",
      "dhar 890\n",
      "atnd 891\n",
      "partha 892\n",
      "arora 893\n",
      "admin 894\n",
      "cover 895\n",
      "latha 896\n",
      "offce 897\n",
      "respondg 898\n",
      "preethi 899\n",
      "deepthi 900\n",
      "indrajit 901\n",
      "concession 902\n",
      "baba 903\n",
      "cnnecting 904\n",
      "prachi 905\n",
      "condct 906\n",
      "sujata 907\n",
      "bacth 908\n",
      "tejeswini 909\n",
      "attedn 910\n",
      "will 911\n",
      "heath 912\n",
      "java 913\n",
      "rajalaxmi 914\n",
      "repnd 915\n",
      "wekknd 916\n",
      "sharvari 917\n",
      "xlr 918\n",
      "candidates 919\n",
      "puja 920\n",
      "shanvi 921\n",
      "enroll 922\n",
      "confrim 923\n",
      "eveng 924\n",
      "shree 925\n",
      "siddu 926\n",
      "gujarat 927\n",
      "whatsap 928\n",
      "ryan 929\n",
      "niharika 930\n",
      "yo 931\n",
      "laxman 932\n",
      "anish 933\n",
      "interview 934\n",
      "saugata 935\n",
      "chakrabarti 936\n",
      "sagar 937\n",
      "dnyaneshwar 938\n",
      "sujmeet 939\n",
      "patnaik 940\n",
      "harjot 941\n",
      "ongole 942\n",
      "veerabhadra 943\n",
      "tonight 944\n",
      "interessted 945\n",
      "annupriya 946\n",
      "jha 947\n",
      "nagarjuna 948\n",
      "watn 949\n",
      "arount 950\n",
      "rnrr 951\n",
      "ragul 952\n",
      "perumal 953\n",
      "manideep 954\n",
      "mandakini 955\n",
      "nandini 956\n",
      "gagandeep 957\n",
      "gowtha 958\n",
      "rajitha 959\n",
      "akash 960\n",
      "sailendra 961\n",
      "varma 962\n",
      "sriram 963\n",
      "jyothi 964\n",
      "mohammad 965\n",
      "idrees 966\n",
      "akansha 967\n",
      "attednded 968\n",
      "ned 969\n",
      "like 970\n",
      "one 971\n",
      "offrd 972\n",
      "apache 973\n",
      "sprk 974\n",
      "finlsed 975\n",
      "borkar 976\n",
      "tues 977\n",
      "travellng 978\n",
      "ajaya 979\n",
      "doctor 980\n",
      "appt 981\n",
      "ur 982\n",
      "website 983\n",
      "gagan 984\n",
      "neded 985\n",
      "speaak 986\n",
      "diconnected 987\n",
      "kajal 988\n",
      "shaha 989\n",
      "customer 990\n",
      "care 991\n",
      "srihari 992\n",
      "ald 993\n",
      "swtchdoff 994\n",
      "jul 995\n",
      "dsf 996\n",
      "nishtha 997\n",
      "update 998\n",
      "jatin 999\n",
      "basavaraj 1000\n",
      "chandra 1001\n",
      "prepare 1002\n",
      "cat 1003\n",
      "kindly 1004\n",
      "prior 1005\n",
      "via 1006\n",
      "ghouse 1007\n",
      "audit 1008\n",
      "shyam 1009\n",
      "comfort 1010\n",
      "infomred 1011\n",
      "response 1012\n",
      "vidoes 1013\n",
      "visit 1014\n",
      "e 1015\n",
      "clarify 1016\n",
      "hope 1017\n",
      "portal 1018\n",
      "aproving 1019\n",
      "les 1020\n",
      "amt 1021\n",
      "registration 1022\n",
      "shilpy 1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sumasree 1024\n",
      "conncted 1025\n",
      "prem 1026\n",
      "fald 1027\n",
      "lon 1028\n",
      "yesterdy 1029\n",
      "swtych 1030\n",
      "anothr 1031\n",
      "strts 1032\n",
      "anitha 1033\n",
      "philips 1034\n",
      "suprt 1035\n",
      "chakri 1036\n",
      "pay 1037\n",
      "arpit 1038\n",
      "sowkhya 1039\n",
      "wednsdy 1040\n",
      "malarvizhi 1041\n",
      "sep 1042\n",
      "vikash 1043\n",
      "sameer 1044\n",
      "vaidya 1045\n",
      "onlne 1046\n",
      "soundarya 1047\n",
      "aksah 1048\n",
      "banerjee 1049\n",
      "chengu 1050\n",
      "behanan 1051\n",
      "bellam 1052\n",
      "notr 1053\n",
      "diconecting 1054\n",
      "pranali 1055\n",
      "raul 1056\n",
      "om 1057\n",
      "site 1058\n",
      "europe 1059\n",
      "donno 1060\n",
      "varun 1061\n",
      "chandu 1062\n",
      "shailee 1063\n",
      "bose 1064\n",
      "onkar 1065\n",
      "khanapure 1066\n",
      "amish 1067\n",
      "see 1068\n",
      "madhav 1069\n",
      "yadagiri 1070\n",
      "rao 1071\n",
      "rafi 1072\n",
      "sivarama 1073\n",
      "sattibabu 1074\n",
      "vinti 1075\n",
      "rastogi 1076\n",
      "shanker 1077\n",
      "den 1078\n",
      "phukan 1079\n",
      "narendra 1080\n",
      "guru 1081\n",
      "lavanya 1082\n",
      "emailid 1083\n",
      "febian 1084\n",
      "correia 1085\n",
      "pwr 1086\n",
      "swth 1087\n",
      "sreenivasa 1088\n",
      "nr 1089\n",
      "placements 1090\n",
      "nagendra 1091\n",
      "wi 1092\n",
      "sudheer 1093\n",
      "kanishka 1094\n",
      "ms 1095\n",
      "dynamics 1096\n",
      "ax 1097\n",
      "vinoth 1098\n",
      "nagappa 1099\n",
      "trid 1100\n",
      "dfrnt 1101\n",
      "numbrs 1102\n",
      "drope 1103\n",
      "satish 1104\n",
      "gurdeep 1105\n",
      "learng 1106\n",
      "thirumala 1107\n",
      "c 1108\n",
      "continue 1109\n",
      "bank 1110\n",
      "sector 1111\n",
      "indrajeet 1112\n",
      "sis 1113\n",
      "marriage 1114\n",
      "posssible 1115\n",
      "koushik 1116\n",
      "shelly 1117\n",
      "docker 1118\n",
      "anisble 1119\n",
      "holiday 1120\n",
      "todya 1121\n",
      "bring 1122\n",
      "friends 1123\n",
      "machine 1124\n",
      "handycap 1125\n",
      "break 1126\n",
      "viswanath 1127\n",
      "anunay 1128\n",
      "pond 1129\n",
      "agust 1130\n",
      "deffintly 1131\n",
      "nagasuresh 1132\n",
      "srilatha 1133\n",
      "reahble 1134\n",
      "pavithra 1135\n",
      "deepa 1136\n",
      "numbe 1137\n",
      "praachi 1138\n",
      "mahabdi 1139\n",
      "jana 1140\n",
      "manoranjan 1141\n",
      "dilemma 1142\n",
      "choose 1143\n",
      "jathin 1144\n",
      "respd 1145\n",
      "shobana 1146\n",
      "mane 1147\n",
      "advaitha 1148\n",
      "swetha 1149\n",
      "swapnil 1150\n",
      "tenserflow 1151\n",
      "gurpreet 1152\n",
      "checkd 1153\n",
      "azhar 1154\n",
      "sayyed 1155\n",
      "zafar 1156\n",
      "congirm 1157\n",
      "anuradha 1158\n",
      "webianr 1159\n",
      "keep 1160\n",
      "well 1161\n",
      "michelle 1162\n",
      "manjula 1163\n",
      "qlickview 1164\n",
      "musrath 1165\n",
      "correct 1166\n",
      "ramm 1167\n",
      "mohanreddy 1168\n",
      "rajeev 1169\n",
      "goel 1170\n",
      "wajid 1171\n",
      "neeraj 1172\n",
      "abdulrahman 1173\n",
      "bhargavi 1174\n",
      "deep 1175\n",
      "discussion 1176\n",
      "banaswadi 1177\n",
      "dheeraj 1178\n",
      "venu 1179\n",
      "damanjeet 1180\n",
      "kaur 1181\n",
      "ammerpet 1182\n",
      "srikar 1183\n",
      "members 1184\n",
      "discount 1185\n",
      "isue 1186\n",
      "profesor 1187\n",
      "dhwaj 1188\n",
      "dronawat 1189\n",
      "sharng 1190\n",
      "jahangir 1191\n",
      "finl 1192\n",
      "yr 1193\n",
      "ramyasri 1194\n",
      "ateend 1195\n",
      "tomorow 1196\n",
      "interenet 1197\n",
      "find 1198\n",
      "broadband 1199\n",
      "hvng 1200\n",
      "proper 1201\n",
      "internet 1202\n",
      "chek 1203\n",
      "reply 1204\n",
      "atttend 1205\n",
      "willl 1206\n",
      "joine 1207\n",
      "din 1208\n",
      "excellr 1209\n",
      "bharath 1210\n",
      "gajjela 1211\n",
      "prev 1212\n",
      "recession 1213\n",
      "viswanathan 1214\n",
      "hrs 1215\n",
      "pritesh 1216\n",
      "alredy 1217\n",
      "velu 1218\n",
      "persnly 1219\n",
      "bnglr 1220\n",
      "schdule 1221\n",
      "persnl 1222\n",
      "kshirendra 1223\n",
      "sahoo 1224\n",
      "bilgi 1225\n",
      "hubli 1226\n",
      "naresh 1227\n",
      "saurav 1228\n",
      "cncting 1229\n",
      "rizwan 1230\n",
      "sayed 1231\n",
      "clarificaton 1232\n",
      "voormila 1233\n",
      "rply 1234\n",
      "mai 1235\n",
      "bandna 1236\n",
      "ganesh 1237\n",
      "loopng 1238\n",
      "vinutha 1239\n",
      "mn 1240\n",
      "shivanth 1241\n",
      "sourse 1242\n",
      "zaheer 1243\n",
      "curse 1244\n",
      "choudhari 1245\n",
      "kolkata 1246\n",
      "shamik 1247\n",
      "nag 1248\n",
      "presently 1249\n",
      "ashok 1250\n",
      "ramanujam 1251\n",
      "atended 1252\n",
      "lalit 1253\n",
      "confirmation 1254\n",
      "whether 1255\n",
      "simran 1256\n",
      "certificate 1257\n",
      "viswa 1258\n",
      "btm 1259\n",
      "veera 1260\n",
      "askng 1261\n",
      "smita 1262\n",
      "old 1263\n",
      "narasimha 1264\n",
      "sharwani 1265\n",
      "bhati 1266\n",
      "wknds 1267\n",
      "daniel 1268\n",
      "attnede 1269\n",
      "jiral 1270\n",
      "dekhtawala 1271\n",
      "mehak 1272\n",
      "kakkar 1273\n",
      "francis 1274\n",
      "xavier 1275\n",
      "wend 1276\n",
      "t 1277\n",
      "attnde 1278\n",
      "tmng 1279\n",
      "buay 1280\n",
      "paresh 1281\n",
      "chaudhari 1282\n",
      "roseleen 1283\n",
      "wrg 1284\n",
      "nitya 1285\n",
      "pradeepti 1286\n",
      "shrivastava 1287\n",
      "accordingly 1288\n",
      "previously 1289\n",
      "ashwin 1290\n",
      "chandwadkar 1291\n",
      "reachlbe 1292\n",
      "soni 1293\n",
      "sabarni 1294\n",
      "devps 1295\n",
      "crporate 1296\n",
      "vishwakarma 1297\n",
      "engd 1298\n",
      "certify 1299\n",
      "person 1300\n",
      "itrstd 1301\n",
      "bhyrappaji 1302\n",
      "inter 1303\n",
      "compare 1304\n",
      "eclr 1305\n",
      "kalyan 1306\n",
      "hold 1307\n",
      "remain 1308\n",
      "jayadev 1309\n",
      "dint 1310\n",
      "sushmit 1311\n",
      "oracle 1312\n",
      "fusion 1313\n",
      "opportunities 1314\n",
      "karan 1315\n",
      "dumbre 1316\n",
      "joydip 1317\n",
      "chakraborty 1318\n",
      "disconneted 1319\n",
      "tambatkar 1320\n",
      "manjunath 1321\n",
      "attrended 1322\n",
      "test 1323\n",
      "respnding 1324\n",
      "noise 1325\n",
      "disturbance 1326\n",
      "shweta 1327\n",
      "connctng 1328\n",
      "merwyn 1329\n",
      "opinion 1330\n",
      "recently 1331\n",
      "january 1332\n",
      "bhanjan 1333\n",
      "sarma 1334\n",
      "shivam 1335\n",
      "book 1336\n",
      "pmi 1337\n",
      "nidhi 1338\n",
      "pavani 1339\n",
      "attndng 1340\n",
      "ashutosh 1341\n",
      "mudgal 1342\n",
      "amal 1343\n",
      "thomas 1344\n",
      "tushar 1345\n",
      "srivastava 1346\n",
      "suprateem 1347\n",
      "nizam 1348\n",
      "followp 1349\n",
      "conatct 1350\n",
      "batcj 1351\n",
      "sriharsha 1352\n",
      "yajuvendra 1353\n",
      "bisht 1354\n",
      "gargi 1355\n",
      "deshpande 1356\n",
      "anupama 1357\n",
      "view 1358\n",
      "sreejith 1359\n",
      "tym 1360\n",
      "organization 1361\n",
      "soumen 1362\n",
      "ghosh 1363\n",
      "delete 1364\n",
      "deepti 1365\n",
      "discueesd 1366\n",
      "nyt 1367\n",
      "prblm 1368\n",
      "siddaraju 1369\n",
      "g 1370\n",
      "arpana 1371\n",
      "analyst 1372\n",
      "finance 1373\n",
      "module 1374\n",
      "yadavujjawal 1375\n",
      "kudlu 1376\n",
      "main 1377\n",
      "road 1378\n",
      "arif 1379\n",
      "archana 1380\n",
      "devendra 1381\n",
      "aqeel 1382\n",
      "mistry 1383\n",
      "sesssion 1384\n",
      "classsroom 1385\n",
      "viresh 1386\n",
      "reable 1387\n",
      "paranjpe 1388\n",
      "nimmi 1389\n",
      "pant 1390\n",
      "mysore 1391\n",
      "sirisha 1392\n",
      "tathagat 1393\n",
      "yrs 1394\n",
      "mohiuddin 1395\n",
      "kushal 1396\n",
      "joshi 1397\n",
      "arjun 1398\n",
      "rohini 1399\n",
      "kochi 1400\n",
      "rashmikant 1401\n",
      "shrivastav 1402\n",
      "sattar 1403\n",
      "wantd 1404\n",
      "sailender 1405\n",
      "point 1406\n",
      "praful 1407\n",
      "malankar 1408\n",
      "tiruttani 1409\n",
      "meanwhile 1410\n",
      "salman 1411\n",
      "piyush 1412\n",
      "sumeet 1413\n",
      "paharia 1414\n",
      "tusdy 1415\n",
      "vishesh 1416\n",
      "worng 1417\n",
      "hememalini 1418\n",
      "ambatch 1419\n",
      "mornign 1420\n",
      "aslam 1421\n",
      "kalyani 1422\n",
      "tripathi 1423\n",
      "emis 1424\n",
      "cc 1425\n",
      "finalize 1426\n",
      "final 1427\n",
      "follow 1428\n",
      "brother 1429\n",
      "classrom 1430\n",
      "thursdy 1431\n",
      "wwant 1432\n",
      "sankeerth 1433\n",
      "havg 1434\n",
      "g. 1435\n",
      "rinda 1436\n",
      "ssbb 1437\n",
      "graduation 1438\n",
      "hemanshu 1439\n",
      "punit 1440\n",
      "tanmai 1441\n",
      "asif 1442\n",
      "wandre 1443\n",
      "paras 1444\n",
      "texted 1445\n",
      "cnectng 1446\n",
      "kasturika 1447\n",
      "saikia 1448\n",
      "wron 1449\n",
      "rama 1450\n",
      "jaya 1451\n",
      "upadhyay 1452\n",
      "bijoy 1453\n",
      "surendranath 1454\n",
      "armaan 1455\n",
      "kohli 1456\n",
      "manager 1457\n",
      "ajinkya 1458\n",
      "statistics 1459\n",
      "samini 1460\n",
      "mathew 1461\n",
      "amerpet 1462\n",
      "sanath 1463\n",
      "ranjith 1464\n",
      "vijarngr 1465\n",
      "mg 1466\n",
      "pan 1467\n",
      "mathad 1468\n",
      "pranjali 1469\n",
      "mandlik 1470\n",
      "sindhu 1471\n",
      "otherwise 1472\n",
      "mittal 1473\n",
      "daughter 1474\n",
      "exler 1475\n",
      "jayaram 1476\n",
      "suparna 1477\n",
      "prince 1478\n",
      "connectd 1479\n",
      "kasare 1480\n",
      "akhil 1481\n",
      "udaysinh 1482\n",
      "drpd 1483\n",
      "rishi 1484\n",
      "janardanareddy 1485\n",
      "selvaa 1486\n",
      "feedback 1487\n",
      "late 1488\n",
      "shal 1489\n",
      "awadhesh 1490\n",
      "poornima 1491\n",
      "jay 1492\n",
      "qa 1493\n",
      "qc 1494\n",
      "sigma 1495\n",
      "sungar 1496\n",
      "monring 1497\n",
      "forward 1498\n",
      "exist 1499\n",
      "balaram 1500\n",
      "kurapati 1501\n",
      "sumeru 1502\n",
      "datta 1503\n",
      ". 1504\n",
      "prashanth 1505\n",
      "preeth 1506\n",
      "councelling 1507\n",
      "shred 1508\n",
      "tensorflow 1509\n",
      "corprt 1510\n",
      "praneeth 1511\n",
      "plaz 1512\n",
      "gurupreet 1513\n",
      "prayash 1514\n",
      "nilesh 1515\n",
      "raut 1516\n",
      "offf 1517\n",
      "liftg 1518\n",
      "cutg 1519\n",
      "cutd 1520\n",
      "shivaji 1521\n",
      "gaikwad 1522\n",
      "rechble 1523\n",
      "madhukar 1524\n",
      "satnam 1525\n",
      "charishma 1526\n",
      "faridabad 1527\n",
      "mitika 1528\n",
      "mahaboob 1529\n",
      "basha 1530\n",
      "ravikanth 1531\n",
      "min 1532\n",
      "agendas 1533\n",
      "samir 1534\n",
      "dutta 1535\n",
      "tryng 1536\n",
      "provd 1537\n",
      "altdy 1538\n",
      "dng 1539\n",
      "tf 1540\n",
      "blockchain 1541\n",
      "harsha 1542\n",
      "tapan 1543\n",
      "bits 1544\n",
      "pilani 1545\n",
      "handson 1546\n",
      "bsy 1547\n",
      "continuous 1548\n",
      "mother 1549\n",
      "admit 1550\n",
      "nirupa 1551\n",
      "singhal 1552\n",
      "debtosh 1553\n",
      "family 1554\n",
      "sahred 1555\n",
      "sharad 1556\n",
      "madhavan 1557\n",
      "sru 1558\n",
      "goyal 1559\n",
      "seminar 1560\n",
      "vishnu 1561\n",
      "content 1562\n",
      "mark 1563\n",
      "seek 1564\n",
      "shatabdi 1565\n",
      "dey 1566\n",
      "autamtn 1567\n",
      "eng 1568\n",
      "options 1569\n",
      "sastry 1570\n",
      "sulagna 1571\n",
      "bhushan 1572\n",
      "anvesh 1573\n",
      "vikram 1574\n",
      "repsnd 1575\n",
      "debashish 1576\n",
      "sankalp 1577\n",
      "long 1578\n",
      "sridhar 1579\n",
      "vanaja 1580\n",
      "jaiswal 1581\n",
      "nlw 1582\n",
      "darshan 1583\n",
      "jk 1584\n",
      "early 1585\n",
      "bathula 1586\n",
      "joing 1587\n",
      "residence 1588\n",
      "powercut 1589\n",
      "inayath 1590\n",
      "navdeep 1591\n",
      "clear 1592\n",
      "doubt 1593\n",
      "manohar 1594\n",
      "lookng 1595\n",
      "iff 1596\n",
      "r.venkatprasad 1597\n",
      "shantanu 1598\n",
      "nithin 1599\n",
      "goutam 1600\n",
      "recrded 1601\n",
      "reetam 1602\n",
      "shreeyash 1603\n",
      "pranay 1604\n",
      "lead 1605\n",
      "capm 1606\n",
      "personal 1607\n",
      "pradha 1608\n",
      "saroja 1609\n",
      "finlse 1610\n",
      "convert 1611\n",
      "kalyankumar 1612\n",
      "wekends 1613\n",
      "bhuyan 1614\n",
      "kadapa 1615\n",
      "veerraju 1616\n",
      "amanchi 1617\n",
      "nisha 1618\n",
      "m.s.c.yuvaraj 1619\n",
      "subash 1620\n",
      "rajan 1621\n",
      "reach 1622\n",
      "anjaneyulu 1623\n",
      "cam 1624\n",
      "sept 1625\n",
      "nirav 1626\n",
      "tuesday 1627\n",
      "little 1628\n",
      "decision 1629\n",
      "nair 1630\n",
      "sudhir 1631\n",
      "mat 1632\n",
      "ranganath 1633\n",
      "sanghavi 1634\n",
      "disconected 1635\n",
      "hemant 1636\n",
      "within 1637\n",
      "saradhi 1638\n",
      "sathish 1639\n",
      "medication 1640\n",
      "insist 1641\n",
      "timg 1642\n",
      "dasarathi 1643\n",
      "intermdt 1644\n",
      "ne 1645\n",
      "novmber 1646\n",
      "dec 1647\n",
      "anees 1648\n",
      "consultancy 1649\n",
      "madurai 1650\n",
      "tie 1651\n",
      "agencies 1652\n",
      "vishwa 1653\n",
      "quality 1654\n",
      "gill 1655\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((lenght, 100))\n",
    "for word, i in tokenizer_obj.word_index.items():\n",
    "    print(word,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in tokenizer_obj.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          165600    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          117248    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 291,169\n",
      "Trainable params: 125,569\n",
      "Non-trainable params: 165,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(lenght,100,weights=[embedding_matrix],input_length=100,trainable=False)) \n",
    "model.add(Dense())\n",
    "#lstm layer\n",
    "model.add(LSTM(128,return_sequences=True,dropout=0.2))\n",
    "\n",
    "#Global Maxpooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model.add(Dense(64,activation='relu')) \n",
    "model.add(Dense(1,activation='sigmoid')) \n",
    "\n",
    "#Add loss function, metrics, optimizer\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[\"acc\"]) \n",
    "\n",
    "#Adding callbacks\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model.h4', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "#Print summary of model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 50).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 50).\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6927 - acc: 0.8498WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 50).\n",
      "6/6 [==============================] - 6s 382ms/step - loss: 0.6926 - acc: 0.8523 - val_loss: 0.6909 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87027, saving model to best_model.h4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.h4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.h4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 257ms/step - loss: 0.6903 - acc: 0.8832 - val_loss: 0.6887 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.87027\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.6883 - acc: 0.8633 - val_loss: 0.6865 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.87027\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 228ms/step - loss: 0.6862 - acc: 0.8605 - val_loss: 0.6844 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.87027\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 244ms/step - loss: 0.6836 - acc: 0.8826 - val_loss: 0.6822 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87027\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 208ms/step - loss: 0.6822 - acc: 0.8541 - val_loss: 0.6800 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87027\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.6795 - acc: 0.8725 - val_loss: 0.6779 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87027\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 2s 303ms/step - loss: 0.6777 - acc: 0.8629 - val_loss: 0.6758 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87027\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 2s 303ms/step - loss: 0.6753 - acc: 0.8701 - val_loss: 0.6737 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.87027\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 226ms/step - loss: 0.6734 - acc: 0.8656 - val_loss: 0.6716 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.87027\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(train_pad),np.array(y_train),batch_size=128,epochs=10,\n",
    "                    validation_data=(np.array(test_pad),np.array(y_test)),verbose=1,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 50).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 50).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 75ms/step - loss: 0.6909 - acc: 0.8674\n",
      "0.8673883676528931\n"
     ]
    }
   ],
   "source": [
    "#loading best model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('best_model.h4')\n",
    "\n",
    "#evaluation \n",
    "_,val_acc = model.evaluate(train_pad,y_train, batch_size=128)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 50).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 50).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[641,   0],\n",
       "       [ 98,   0]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(train_pad)\n",
    "y_pred = (y_pred > 0.5)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train , y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[161,   0],\n",
       "       [ 24,   0]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_pad)\n",
    "y_pred = (y_pred > 0.5)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test , y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
