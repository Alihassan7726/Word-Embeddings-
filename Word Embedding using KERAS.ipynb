{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "pd.set_option(\"max_columns\",100)\n",
    "pd.set_option('display.width',1000)\n",
    "pd.set_option('max_colwidth', 1000) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.path.join('C:/BEPEC Python Material/NLP project/','Clean_data.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status information</th>\n",
       "      <th>Clean-status</th>\n",
       "      <th>clean_sent</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raja</td>\n",
       "      <td>hyderabad</td>\n",
       "      <td>0</td>\n",
       "      <td>14/8/prema: share me details, available in evng 18/8/prema: postponed the plans for training currently 9/11/prema: not interested now</td>\n",
       "      <td>[prema, share, detail, available, evng, prema, postpone, plan, train, currently, prema, not, interest]</td>\n",
       "      <td>prema share detail available evng prema postpone plan train currently prema not interest</td>\n",
       "      <td>hyderabad prema share detail available evng prema postpone plan train currently prema not interest Raja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anirudh Reddy</td>\n",
       "      <td>pune</td>\n",
       "      <td>0</td>\n",
       "      <td>14/8/prema: cal me tmrw, shared details to email 16/8/prema: share details to email, will check n revert 18/8/prema: received your email, i'm looking for ASQ certification</td>\n",
       "      <td>[prema, cal, share, detail, email, prema, share, detail, email, check, n, revert, prema, receive, email, look, asq, certification]</td>\n",
       "      <td>prema cal share detail email prema share detail email check n revert prema receive email look asq certification</td>\n",
       "      <td>pune prema cal share detail email prema share detail email check n revert prema receive email look asq certification Anirudh Reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sapna Dewani</td>\n",
       "      <td>bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>16|AuG|moHan:rnr</td>\n",
       "      <td>[aug, mohan, rnr]</td>\n",
       "      <td>aug mohan rnr</td>\n",
       "      <td>bangalore aug mohan rnr Sapna Dewani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suresh</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>0</td>\n",
       "      <td>14/8/17(Surendra):i want only Server 16|AuG|moHan:cal busy 17|AuG|moHan:reg for server</td>\n",
       "      <td>[surendra, want, server, aug, mohan, cal, busy, aug, mohan, reg, server]</td>\n",
       "      <td>surendra want server aug mohan cal busy aug mohan reg server</td>\n",
       "      <td>mumbai surendra want server aug mohan cal busy aug mohan reg server suresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akshay Shinde</td>\n",
       "      <td>hyderabad</td>\n",
       "      <td>0</td>\n",
       "      <td>14/8/prema:rnr 16/8/prema: gave info, he said he will revert in 1hr 30/8/prema: planning for next month, share details</td>\n",
       "      <td>[prema, rnr, prema, give, info, say, revert, hr, prema, plan, next, month, share, detail]</td>\n",
       "      <td>prema rnr prema give info say revert hr prema plan next month share detail</td>\n",
       "      <td>hyderabad prema rnr prema give info say revert hr prema plan next month share detail Akshay Shinde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lead Name   Location  Status                                                                                                                                                            Status information                                                                                                                        Clean-status                                                                                                       clean_sent                                                                                                                                Text\n",
       "0           Raja  hyderabad        0                                        14/8/prema: share me details, available in evng 18/8/prema: postponed the plans for training currently 9/11/prema: not interested now                              [prema, share, detail, available, evng, prema, postpone, plan, train, currently, prema, not, interest]                         prema share detail available evng prema postpone plan train currently prema not interest                             hyderabad prema share detail available evng prema postpone plan train currently prema not interest Raja\n",
       "1  Anirudh Reddy       pune        0  14/8/prema: cal me tmrw, shared details to email 16/8/prema: share details to email, will check n revert 18/8/prema: received your email, i'm looking for ASQ certification  [prema, cal, share, detail, email, prema, share, detail, email, check, n, revert, prema, receive, email, look, asq, certification]  prema cal share detail email prema share detail email check n revert prema receive email look asq certification  pune prema cal share detail email prema share detail email check n revert prema receive email look asq certification Anirudh Reddy\n",
       "2   Sapna Dewani  bangalore        1                                                                                                                                                             16|AuG|moHan:rnr                                                                                                                   [aug, mohan, rnr]                                                                                                    aug mohan rnr                                                                                                bangalore aug mohan rnr Sapna Dewani\n",
       "3         suresh     mumbai        0                                                                                       14/8/17(Surendra):i want only Server 16|AuG|moHan:cal busy 17|AuG|moHan:reg for server                                                            [surendra, want, server, aug, mohan, cal, busy, aug, mohan, reg, server]                                                     surendra want server aug mohan cal busy aug mohan reg server                                                          mumbai surendra want server aug mohan cal busy aug mohan reg server suresh\n",
       "4  Akshay Shinde  hyderabad        0                                                       14/8/prema:rnr 16/8/prema: gave info, he said he will revert in 1hr 30/8/prema: planning for next month, share details                                           [prema, rnr, prema, give, info, say, revert, hr, prema, plan, next, month, share, detail]                                       prema rnr prema give info say revert hr prema plan next month share detail                                  hyderabad prema rnr prema give info say revert hr prema plan next month share detail Akshay Shinde"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(df['Text'],df['Status '],test_size = 0.2,random_state = 42,shuffle= True,\n",
    "                                                      stratify = df['Status '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(739,)\n",
      "(185,)\n",
      "(739,)\n",
      "(185,)\n",
      "0    161\n",
      "1     24\n",
      "Name: Status , dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(df):\n",
    "    corpus=[]\n",
    "    for text in tqdm(df):\n",
    "        words=[word for word in word_tokenize(text)]\n",
    "        corpus.append(words)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 739/739 [00:00<00:00, 3317.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['hyderabad',\n",
       "  'surendra',\n",
       "  'rnr',\n",
       "  'surendra',\n",
       "  'call',\n",
       "  'surendra',\n",
       "  'dis',\n",
       "  'month',\n",
       "  'iam',\n",
       "  'busy',\n",
       "  'get',\n",
       "  'back',\n",
       "  'soon',\n",
       "  'surendra',\n",
       "  'share',\n",
       "  'detail',\n",
       "  'revert',\n",
       "  'surendra',\n",
       "  'iam',\n",
       "  'interest',\n",
       "  'get',\n",
       "  'back',\n",
       "  'Hiren'],\n",
       " ['bangalore',\n",
       "  'gowtham',\n",
       "  'rnr',\n",
       "  'gowtham',\n",
       "  'rnr',\n",
       "  'gowtham',\n",
       "  'detail',\n",
       "  'shrd',\n",
       "  'check',\n",
       "  'n',\n",
       "  'cnfrm',\n",
       "  'gowtham',\n",
       "  'call',\n",
       "  'u',\n",
       "  'gowtham',\n",
       "  'rnr',\n",
       "  'gowtham',\n",
       "  'not',\n",
       "  'rchble',\n",
       "  'soma',\n",
       "  'currently',\n",
       "  'not',\n",
       "  'interest',\n",
       "  'Sajal',\n",
       "  'Roy'],\n",
       " ['Hyderabad',\n",
       "  'surendra',\n",
       "  'call',\n",
       "  'saturday',\n",
       "  'pm',\n",
       "  'surendra',\n",
       "  'busy',\n",
       "  'surendra',\n",
       "  'call',\n",
       "  'not',\n",
       "  'connect',\n",
       "  'Nikhil',\n",
       "  'Futane'],\n",
       " ['delhi',\n",
       "  'june',\n",
       "  'mohan',\n",
       "  'l',\n",
       "  'june',\n",
       "  'mohan',\n",
       "  'misd',\n",
       "  'today',\n",
       "  'mrg',\n",
       "  'try',\n",
       "  'evng',\n",
       "  'july',\n",
       "  'mohan',\n",
       "  'atteded',\n",
       "  'demo',\n",
       "  'check',\n",
       "  'trail',\n",
       "  'today',\n",
       "  'Barun',\n",
       "  'Dev'],\n",
       " ['bangalore',\n",
       "  'soma',\n",
       "  'detaills',\n",
       "  'share',\n",
       "  'soma',\n",
       "  'say',\n",
       "  'next',\n",
       "  'month',\n",
       "  'Pooja',\n",
       "  'TThuse']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = create_corpus(X_train)\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  8,\n",
       "  2,\n",
       "  118,\n",
       "  72,\n",
       "  28,\n",
       "  25,\n",
       "  37,\n",
       "  22,\n",
       "  174,\n",
       "  2,\n",
       "  6,\n",
       "  7,\n",
       "  46,\n",
       "  2,\n",
       "  28,\n",
       "  30,\n",
       "  37,\n",
       "  22,\n",
       "  564],\n",
       " [10,\n",
       "  13,\n",
       "  1,\n",
       "  13,\n",
       "  1,\n",
       "  13,\n",
       "  7,\n",
       "  150,\n",
       "  17,\n",
       "  49,\n",
       "  122,\n",
       "  13,\n",
       "  8,\n",
       "  32,\n",
       "  13,\n",
       "  1,\n",
       "  13,\n",
       "  9,\n",
       "  247,\n",
       "  5,\n",
       "  123,\n",
       "  9,\n",
       "  30,\n",
       "  565,\n",
       "  391],\n",
       " [12, 2, 8, 130, 29, 2, 25, 2, 8, 9, 38, 566, 567],\n",
       " [45,\n",
       "  15,\n",
       "  4,\n",
       "  175,\n",
       "  15,\n",
       "  4,\n",
       "  297,\n",
       "  21,\n",
       "  86,\n",
       "  43,\n",
       "  59,\n",
       "  11,\n",
       "  4,\n",
       "  248,\n",
       "  14,\n",
       "  17,\n",
       "  163,\n",
       "  21,\n",
       "  568,\n",
       "  569],\n",
       " [10, 5, 570, 6, 5, 65, 73, 72, 571, 572]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_obj = Tokenizer() #turns each text into either a sequence of integers \n",
    "                            #(each integer being the index of a token in a dictionary)\n",
    "\n",
    "tokenizer_obj.fit_on_texts(corpus) # methods `texts_to_sequences` or `texts_to_matrix`.\n",
    "sequences=tokenizer_obj.texts_to_sequences(corpus) # Transforms each text in texts to a sequence of integers.\n",
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739\n",
      "(739, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   37,   22,  564],\n",
       "       [   0,    0,    0, ...,   30,  565,  391],\n",
       "       [   0,    0,    0, ...,   38,  566,  567],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1651, 1652, 1653],\n",
       "       [   0,    0,    0, ...,  102,  148, 1655],\n",
       "       [   0,    0,    0, ...,    6,    7,  274]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_pad=pad_sequences(sequences,maxlen=50,truncating='post',padding='pre') # lists to array form\n",
    "print(len(corpus))\n",
    "print(tweet_pad.shape)\n",
    "tweet_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 1656\n"
     ]
    }
   ],
   "source": [
    "## Parameters for embedding layer\n",
    "DIM = 100\n",
    "MAX_LEN = 50\n",
    "\n",
    "word_index=tokenizer_obj.word_index\n",
    "word_index\n",
    "lenght = len(word_index)+1\n",
    "print('Number of unique words:',lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(lenght , DIM , input_length = MAX_LEN))\n",
    "model.compile('adam' , 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           165600    \n",
      "=================================================================\n",
      "Total params: 165,600\n",
      "Trainable params: 165,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(739, 50, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        ...,\n",
       "        [ 0.00152206, -0.0441224 , -0.04358938, ...,  0.04217423,\n",
       "         -0.02613878, -0.04361856],\n",
       "        [-0.01109309, -0.01416742, -0.01420488, ...,  0.00674293,\n",
       "          0.02230883,  0.00760418],\n",
       "        [-0.04108956, -0.00382336, -0.04764713, ..., -0.018609  ,\n",
       "         -0.02912555,  0.01139009]],\n",
       "\n",
       "       [[-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        ...,\n",
       "        [ 0.01342232, -0.01952289, -0.01594447, ..., -0.03780969,\n",
       "         -0.02861942,  0.04686308],\n",
       "        [ 0.00266329,  0.02327733,  0.01704453, ..., -0.01031478,\n",
       "         -0.0457242 ,  0.02950219],\n",
       "        [-0.00352009,  0.00533887,  0.03599962, ...,  0.02962787,\n",
       "         -0.00845417, -0.0112422 ]],\n",
       "\n",
       "       [[-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        ...,\n",
       "        [-0.01085382,  0.04824777,  0.03705758, ..., -0.0082676 ,\n",
       "         -0.03324155, -0.01379598],\n",
       "        [-0.04219805,  0.03125021, -0.01144435, ..., -0.01020752,\n",
       "         -0.03459811,  0.02329316],\n",
       "        [-0.01544169, -0.02582523,  0.01171406, ..., -0.00954752,\n",
       "         -0.03633649,  0.00746704]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        ...,\n",
       "        [-0.0354965 ,  0.04746615, -0.01945424, ..., -0.01572684,\n",
       "         -0.02398666, -0.03215583],\n",
       "        [ 0.00915152, -0.00107851,  0.00082762, ..., -0.00029803,\n",
       "          0.03848306, -0.01642569],\n",
       "        [ 0.03223206, -0.03610816,  0.01242838, ..., -0.00387205,\n",
       "          0.04009925,  0.03734794]],\n",
       "\n",
       "       [[-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        ...,\n",
       "        [ 0.01330327,  0.0136175 , -0.03726985, ...,  0.01599306,\n",
       "         -0.01485456, -0.03982164],\n",
       "        [-0.00544592, -0.02533512,  0.01335101, ...,  0.0285073 ,\n",
       "         -0.01430978,  0.02174753],\n",
       "        [ 0.00952535,  0.04338274, -0.01146457, ..., -0.02200558,\n",
       "         -0.02234067, -0.00853588]],\n",
       "\n",
       "       [[-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        [-0.04681064,  0.02246303, -0.02770041, ...,  0.03261289,\n",
       "         -0.02865309,  0.00949977],\n",
       "        ...,\n",
       "        [-0.0238278 ,  0.0030818 ,  0.01725155, ...,  0.01699578,\n",
       "         -0.02874896, -0.00775776],\n",
       "        [ 0.03330871, -0.04033563, -0.00666832, ...,  0.00818123,\n",
       "          0.01974675, -0.00877515],\n",
       "        [ 0.01924748,  0.03239605,  0.00236657, ...,  0.04996163,\n",
       "          0.00115155,  0.00629314]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = model.predict(tweet_pad)\n",
    "print(array.shape)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
